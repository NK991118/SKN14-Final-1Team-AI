{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8053bd4e-3cc2-49fb-8077-3c86447d8364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting regex (from vllm)\n",
      "  Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting cachetools (from vllm)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Downloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
      "Collecting tqdm (from vllm)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting blake3 (from vllm)\n",
      "  Downloading blake3-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (217 bytes)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.55.2 (from vllm)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting tokenizers>=0.21.1 (from vllm)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting protobuf (from vllm)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi-0.117.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting aiohttp (from vllm)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting openai>=1.99.1 (from vllm)\n",
      "  Downloading openai-1.108.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pydantic>=2.11.7 (from vllm)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.0.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
      "  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines_core==0.2.11 (from vllm)\n",
      "  Downloading outlines_core-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting diskcache==5.6.3 (from vllm)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.23 (from vllm)\n",
      "  Downloading xgrammar-0.1.23-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.16.1)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (26.3.0)\n",
      "Collecting msgspec (from vllm)\n",
      "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
      "Collecting einops (from vllm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.11.0 (from vllm)\n",
      "  Downloading compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.19.0 (from vllm)\n",
      "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cloudpickle (from vllm)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\n",
      "Collecting scipy (from vllm)\n",
      "  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting pybase64 (from vllm)\n",
      "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting cbor2 (from vllm)\n",
      "  Downloading cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting setproctitle (from vllm)\n",
      "  Downloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
      "Collecting openai-harmony>=0.0.3 (from vllm)\n",
      "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting numba==0.61.2 (from vllm)\n",
      "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading ray-2.49.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting torch==2.8.0 (from vllm)\n",
      "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchaudio==2.8.0 (from vllm)\n",
      "  Downloading torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting torchvision==0.23.0 (from vllm)\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.32.post1 (from vllm)\n",
      "  Downloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting frozendict (from compressed-tensors==0.11.0->vllm)\n",
      "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
      "Collecting astor (from depyf==0.19.0->vllm)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dill (from depyf==0.19.0->vllm)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.11.3->vllm) (24.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0->vllm)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch==2.8.0->vllm)\n",
      "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch==2.8.0->vllm) (77.0.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting starlette<0.49.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Collecting jinja2 (from torch==2.8.0->vllm)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvicorn-0.36.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->vllm)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->vllm)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->vllm)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->vllm)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->vllm)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->vllm)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.23.0)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.99.1->vllm) (1.7.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.99.1->vllm)\n",
      "  Downloading jiter-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (1.3.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.11.7->vllm)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.11.7->vllm)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.11.7->vllm)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=7.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading cupy_cuda12x-13.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.55.2->vllm)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading typer-0.19.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cloud_cli-0.2.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.8.0->vllm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.23.1)\n",
      "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.8.0->vllm) (1.3.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting soxr>=0.5.0 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading soxr-1.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading sentry_sdk-2.38.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl (436.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m436.4/436.4 MB\u001B[0m \u001B[31m255.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n",
      "Downloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m449.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading outlines_core-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m315.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m888.1/888.1 MB\u001B[0m \u001B[31m214.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m246.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.6/8.6 MB\u001B[0m \u001B[31m312.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m117.2/117.2 MB\u001B[0m \u001B[31m272.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading xgrammar-0.1.23-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.9/7.9 MB\u001B[0m \u001B[31m227.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m594.3/594.3 MB\u001B[0m \u001B[31m263.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.2/10.2 MB\u001B[0m \u001B[31m304.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m88.0/88.0 MB\u001B[0m \u001B[31m287.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m954.8/954.8 kB\u001B[0m \u001B[31m307.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m706.8/706.8 MB\u001B[0m \u001B[31m268.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m193.1/193.1 MB\u001B[0m \u001B[31m301.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m372.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.6/63.6 MB\u001B[0m \u001B[31m250.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m267.5/267.5 MB\u001B[0m \u001B[31m340.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m288.2/288.2 MB\u001B[0m \u001B[31m305.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m287.2/287.2 MB\u001B[0m \u001B[31m319.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m322.4/322.4 MB\u001B[0m \u001B[31m383.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m39.3/39.3 MB\u001B[0m \u001B[31m385.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m155.5/155.5 MB\u001B[0m \u001B[31m302.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fastapi-0.117.1-py3-none-any.whl (95 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m323.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m563.4/563.4 kB\u001B[0m \u001B[31m119.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.0/15.0 MB\u001B[0m \u001B[31m319.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m388.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading openai-1.108.2-py3-none-any.whl (948 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m948.4/948.4 kB\u001B[0m \u001B[31m387.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m377.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.0/54.0 MB\u001B[0m \u001B[31m359.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.8/42.8 MB\u001B[0m \u001B[31m400.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m522.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading ray-2.49.2-cp311-cp311-manylinux2014_x86_64.whl (70.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m70.1/70.1 MB\u001B[0m \u001B[31m325.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m410.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m799.0/799.0 kB\u001B[0m \u001B[31m327.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m439.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.6/11.6 MB\u001B[0m \u001B[31m354.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading blake3-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.4/12.4 MB\u001B[0m \u001B[31m416.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m35.9/35.9 MB\u001B[0m \u001B[31m372.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m422.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
      "Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m501.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jiter-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m331.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (429 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uvicorn-0.36.0-py3-none-any.whl (67 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp311-cp311-manylinux2014_x86_64.whl (113.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m113.0/113.0 MB\u001B[0m \u001B[31m266.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading fastapi_cloud_cli-0.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.3/6.3 MB\u001B[0m \u001B[31m337.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m336.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading soxr-1.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Downloading typer-0.19.1-py3-none-any.whl (46 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m359.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m950.6/950.6 kB\u001B[0m \u001B[31m386.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sentry_sdk-2.38.0-py2.py3-none-any.whl (370 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, nvidia-cusparselt-cu12, fastrlock, xxhash, websockets, uvloop, tzdata, typing-inspection, triton, tqdm, soxr, shellingham, setproctitle, sentry-sdk, sentencepiece, scipy, safetensors, rignore, regex, python-multipart, python-dotenv, pydantic-core, pycountry, pybase64, pyarrow, protobuf, propcache, partial-json-parser, outlines_core, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, multidict, msgspec, msgpack, mdurl, llvmlite, llguidance, lark, jiter, jinja2, interegular, httptools, hf-xet, frozenlist, frozendict, einops, dnspython, diskcache, dill, cupy-cuda12x, cloudpickle, click, cbor2, cachetools, blake3, astor, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, tiktoken, starlette, soundfile, pydantic, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, multiprocess, markdown-it-py, huggingface-hub, gguf, email-validator, depyf, aiosignal, tokenizers, rich, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, openai, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, aiohttp, typer, transformers, torch, rich-toolkit, ray, xgrammar, xformers, torchvision, torchaudio, mistral_common, fastapi-cloud-cli, fastapi-cli, datasets, compressed-tensors, vllm\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.8.55\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.55:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.55\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.25.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.25.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.25.1\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.55\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.55:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.55\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.13.0.11\n",
      "    Uninstalling nvidia-cufile-cu12-1.13.0.11:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.3.14\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.3.14:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.7.53\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.7.53:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.41\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.41:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.8.0.87\n",
      "    Uninstalling nvidia-cudnn-cu12-9.8.0.87:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.8.0.87\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.2.55\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.2.55:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0.dev20250319+cu128\n",
      "    Uninstalling torch-2.8.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torch-2.8.0.dev20250319+cu128\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.22.0.dev20250319+cu128\n",
      "    Uninstalling torchvision-0.22.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torchvision-0.22.0.dev20250319+cu128\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.6.0.dev20250319+cu128\n",
      "    Uninstalling torchaudio-2.6.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torchaudio-2.6.0.dev20250319+cu128\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 astor-0.8.1 blake3-1.0.6 cachetools-6.2.0 cbor2-5.7.0 click-8.3.0 cloudpickle-3.1.1 compressed-tensors-0.11.0 cupy-cuda12x-13.6.0 datasets-4.1.1 depyf-0.19.0 dill-0.4.0 diskcache-5.6.3 dnspython-2.8.0 einops-0.8.1 email-validator-2.3.0 fastapi-0.117.1 fastapi-cli-0.0.13 fastapi-cloud-cli-0.2.0 fastrlock-0.8.3 frozendict-2.4.6 frozenlist-1.7.0 gguf-0.17.1 hf-xet-1.1.10 httptools-0.6.4 huggingface-hub-0.35.0 interegular-0.3.3 jinja2-3.1.6 jiter-0.11.0 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 markdown-it-py-4.0.0 mdurl-0.1.2 mistral_common-1.8.5 msgpack-1.1.1 msgspec-0.19.0 multidict-6.6.4 multiprocess-0.70.16 ninja-1.13.0 numba-0.61.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 openai-1.108.2 openai-harmony-0.0.4 opencv-python-headless-4.12.0.88 outlines_core-0.2.11 pandas-2.3.2 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 propcache-0.3.2 protobuf-6.32.1 py-cpuinfo-9.0.0 pyarrow-21.0.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 python-dotenv-1.1.1 python-multipart-0.0.20 pytz-2025.2 ray-2.49.2 regex-2025.9.18 rich-14.1.0 rich-toolkit-0.15.1 rignore-0.6.4 safetensors-0.6.2 scipy-1.16.2 sentencepiece-0.2.1 sentry-sdk-2.38.0 setproctitle-1.3.7 shellingham-1.5.4 soundfile-0.13.1 soxr-1.0.0 starlette-0.48.0 tiktoken-0.11.0 tokenizers-0.22.1 torch-2.8.0 torchaudio-2.8.0 torchvision-0.23.0 tqdm-4.67.1 transformers-4.56.2 triton-3.4.0 typer-0.19.1 typing-inspection-0.4.1 tzdata-2025.2 uvicorn-0.36.0 uvloop-0.21.0 vllm-0.10.2 watchfiles-1.1.0 websockets-15.0.1 xformers-0.0.32.post1 xgrammar-0.1.23 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4fa80d-56cd-4d27-9fae-577c96684038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.1.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython -m pip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy\n",
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9e4bb-9a8a-455c-a3f5-baf9d7400925",
   "metadata": {},
   "source": [
    "## 1. 테스트 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61989ad6-85be-413e-ad63-e7a9e0f8016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-23 01:51:14 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from datasets import load_dataset, Dataset\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e653d1b-0a38-4527-af4c-94715d8dffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset_from_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = json.load(f)\n",
    "        return data\n",
    "\n",
    "# 사용 예시\n",
    "dataset = load_train_dataset_from_json(\"qwen3_company_train_dataset_combined.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ecd40f-f008-4278-95f1-efed115df2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d197677-b2fb-4990-9158-36044e9fa6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a36266-ac25-4d0f-b4ee-e48668eef2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 비율 설정\n",
    "test_ratio = 1\n",
    "\n",
    "# 전체 길이와 테스트 데이터 크기 계산\n",
    "total_len = len(dataset)\n",
    "test_size = int(total_len * test_ratio)\n",
    "\n",
    "# 앞에서부터 테스트 데이터, 나머지는 학습 데이터\n",
    "test_indices = list(range(test_size))\n",
    "train_indices = list(range(test_size, total_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6d7199-0f06-4f32-8aa2-d564cc820def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '개발 프로세스의 Git 워크플로우에서 `feature/{기능명}` 브랜치 생성 시 주의해야 할 점은 무엇인가요?',\n",
       "  'role': 'user'},\n",
       " {'content': '<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"개발 프로세스 Git 워크플로우에서 feature 브랜치 생성 시 주의사항\"}}</tool_call>',\n",
       "  'role': 'assistant'},\n",
       " {'content': '<tool_response>검색 결과:\\n-----\\n### 3.3. 성능 최적화\\n- **Lazy Loading**: 필요할 때만 컴포넌트를 로드하여 초기 로딩 속도 개선\\n- **Memoization**: React의 `useMemo` 또는 `React.memo`를 사용하여 불필요한 리렌더링 방지\\n\\n## 4. 개발 프로세스\\n\\n### 4.1. Git 워크플로우\\n- **브랜치 전략**: 기능 개발 시 `feature/{기능명}` 브랜치 생성\\n- **Pull Request**: 코드 리뷰 후 `main` 브랜치에 병합\\n\\n### 4.2. 코드 리뷰\\n- **리뷰 기준**: 코드 가독성, 성능, 보안 및 버그 여부 확인\\n- **피드백 반영**: 리뷰어의 피드백을 수용하여 코드 수정\\n\\n### 4.3. 테스트\\n- **유닛 테스트**: Jest 또는 Mocha를 사용하여 컴포넌트 단위 테스트 작성\\n- **E2E 테스트**: Cypress 또는 Selenium을 사용하여 사용자 흐름 테스트\\n\\n## 5. 배포 및 운영 [[ref1]]\\n<!-- 회사: 코드노바 | 대상: 사원(프론트엔드) | 작성일: 2025-08-29 -->\\n# 빌드/배포 가이드\\n분류: frontend | 회사: 코드노바 | 버전: v1.0 | 작성일: 2025-08-29\\n\\n---\\n\\n## 1. 빌드 준비\\n\\n### 1.1 환경 설정\\n- **Node.js 설치**: 최신 LTS 버전을 설치합니다.\\n- **패키지 매니저**: npm 또는 yarn을 설치합니다.\\n\\n### 1.2 프로젝트 클론\\n- GitHub에서 프로젝트를 클론합니다.\\n- `git clone [레포지토리 URL]` 명령어를 사용합니다.\\n\\n### 1.3 의존성 설치\\n- 프로젝트 디렉토리로 이동 후, 의존성을 설치합니다.\\n- `npm install` 또는 `yarn install` 명령어를 실행합니다.\\n\\n## 2. 빌드 프로세스\\n\\n### 2.1 빌드 명령어 실행\\n- 다음 명령어를 사용하여 빌드를 실행합니다.\\n- `npm run build` 또는 `yarn build` 명령어를 사용합니다. [[ref2]]\\n### 2.2. 첫 주 일정\\n- **오리엔테이션 참석**: 회사의 비전, 문화 및 정책에 대한 오리엔테이션에 참석합니다.\\n- **팀 미팅 참여**: 매주 열리는 팀 미팅에 참석하여 현재 진행 중인 프로젝트에 대한 이해를 높입니다.\\n- **멘토 지정**: 멘토와의 정기적인 미팅을 통해 질문하고 피드백을 받습니다.\\n\\n## 3. 도구 및 기술 스택\\n### 3.1. 필수 도구\\n- **버전 관리 시스템**: Git을 사용하여 코드 변경 사항을 관리합니다.\\n- **프로젝트 관리 도구**: Jira 또는 Trello를 사용하여 작업을 관리합니다.\\n- **커뮤니케이션 도구**: Slack을 통해 팀원들과 소통합니다.\\n\\n### 3.2. 기술 스택\\n- **프론트엔드 프레임워크**: React 또는 Vue.js를 사용합니다.\\n- **스타일링**: CSS 또는 CSS-in-JS 라이브러리를 활용합니다.\\n- **테스트 도구**: Jest 또는 Cypress를 사용하여 테스트를 수행합니다. [[ref3]]\\n## 5. 배포 및 운영\\n\\n### 5.1. CI/CD\\n- **자동화된 빌드**: GitHub Actions 또는 Jenkins를 사용하여 코드 푸시 시 자동 빌드 및 테스트 수행\\n- **배포**: 성공적인 빌드 후 자동으로 스테이징 및 프로덕션 환경에 배포\\n\\n### 5.2. 모니터링\\n- **성능 모니터링**: Google Analytics 또는 Sentry를 사용하여 애플리케이션 성능 및 오류 모니터링\\n\\n## 6. 결론\\n코드노바의 프론트엔드 아키텍처는 사용자 경험을 최우선으로 하며, 개발자의 생산성을 높이기 위해 설계되었습니다. 위의 원칙과 프로세스를 준수하여 개발에 임해 주시기 바랍니다.\\n\\n---\\n\\n다음 개정 제안: 프론트엔드 아키텍처 문서에 사용자 피드백을 반영하여 지속적으로 업데이트할 필요가 있습니다. [[ref4]]\\n## 6. 의존성 관리\\n- **패키지 업데이트**: 사용하는 라이브러리와 패키지는 정기적으로 업데이트하여 최신 보안 패치를 적용합니다.\\n- **취약점 스캐닝**: 의존성에 대한 취약점 스캐닝 도구를 사용하여 보안 취약점을 사전 예방적으로 점검합니다.\\n\\n## 7. 오류 처리\\n- **사용자 친화적인 오류 메시지**: 오류 발생 시, 사용자에게는 일반적인 오류 메시지만 표시하고, 내부 정보는 노출하지 않도록 합니다.\\n- **로깅 및 모니터링**: 오류 발생 시, 로그를 기록하고, 이를 통해 보안 사고를 추적할 수 있도록 합니다.\\n\\n## 8. 배포 보안\\n- **배포 환경 설정**: 배포 환경은 개발 환경과 분리하여 설정하고, 필요한 경우 방화벽을 설정합니다.\\n- **CI/CD 파이프라인 보안**: CI/CD 파이프라인의 접근 권한을 제한하고, 보안 점검을 자동화하여 배포 전 검증합니다. [[ref5]]\\n<!-- 회사: 코드노바 | 대상: 사원(프론트엔드) | 작성일: 2025-08-29 -->\\n# 프로젝트/제품 릴리즈 노트 관리 문서\\n분류: frontend | 회사: 코드노바 | 버전: v1.0 | 작성일: 2025-08-29\\n\\n---\\n\\n## 1. 릴리즈 노트 개요\\n\\n릴리즈 노트는 제품의 새로운 기능, 개선 사항, 버그 수정 및 기타 중요한 정보를 사용자와 팀원들에게 전달하는 문서입니다. 이 문서는 프론트엔드 팀이 프로젝트 또는 제품의 릴리즈를 관리하고 기록하는 데 도움을 줍니다.\\n\\n## 2. 릴리즈 노트 작성 단계\\n\\n### 2.1. 릴리즈 준비\\n\\n- [ ] 릴리즈 일정 확인\\n- [ ] 새로운 기능 및 수정 사항 목록 작성\\n- [ ] 관련 팀원에게 정보 요청 (디자인, 백엔드 등)\\n\\n### 2.2. 릴리즈 내용 정리 [[ref6]]\\n### 2.2. 릴리즈 내용 정리\\n\\n- [ ] 새로운 기능\\n  - 기능 설명: 각 기능에 대한 간단한 설명 및 사용 방법\\n  - 검증 포인트: 기능이 제대로 작동하는지 확인할 체크리스트\\n  \\n- [ ] 개선 사항\\n  - 개선 내용: 기존 기능의 개선 사항 설명\\n  - 검증 포인트: 개선된 기능이 예상대로 작동하는지 확인할 체크리스트\\n\\n- [ ] 버그 수정\\n  - 수정된 버그 목록: 수정된 버그의 설명 및 해결 방법\\n  - 검증 포인트: 수정된 버그가 재발생하지 않는지 확인할 체크리스트\\n\\n### 2.3. 릴리즈 노트 작성\\n\\n- [ ] 릴리즈 노트 템플릿 활용\\n  - 템플릿에 맞춰 작성하며, 각 항목에 대한 자세한 설명 추가\\n- [ ] 문서 검토\\n  - 팀원들과 함께 내용 검토 및 피드백 받기\\n  - 필요한 수정 사항 반영\\n\\n### 2.4. 릴리즈 노트 배포 [[ref7]]\\n### 2.2. 폴더 구조\\n- **src/**: 소스 코드 디렉토리\\n  - **components/**: 재사용 가능한 UI 컴포넌트\\n  - **pages/**: 각 페이지에 해당하는 컴포넌트\\n  - **services/**: API 호출 및 비즈니스 로직\\n  - **assets/**: 이미지, 아이콘 및 기타 정적 파일\\n  - **styles/**: 전역 스타일 및 테마 설정\\n\\n## 3. 개발 원칙\\n\\n### 3.1. 코드 가독성\\n- **명확한 네이밍**: 변수 및 함수의 이름은 그 역할을 명확히 나타내도록 설정\\n- **주석 작성**: 복잡한 로직이나 중요한 결정 사항에는 주석 추가\\n\\n### 3.2. 컴포넌트 재사용성\\n- **작고 독립적인 컴포넌트**: 각 컴포넌트는 하나의 기능만 수행하도록 설계\\n- **props 활용**: 필요한 데이터는 props를 통해 전달하여 컴포넌트 간의 의존성을 최소화 [[ref8]]</tool_response>',\n",
       "  'role': 'user'},\n",
       " {'content': '개발 프로세스의 Git 워크플로우에서 `feature/{기능명}` 브랜치 생성 시 주의해야 할 점은 다음과 같습니다.\\n\\n1. 브랜치 명명 규칙을 명확히 준수하여 기능명을 직관적이고 일관성 있게 작성해야 합니다.\\n2. 기능 개발에 집중할 수 있도록 해당 브랜치는 독립적으로 관리하며, 불필요한 변경 사항이 포함되지 않도록 주의해야 합니다.\\n3. 기능 개발 완료 후에는 반드시 코드 리뷰를 거쳐 `main` 브랜치에 병합하도록 합니다.\\n4. 병합 전에는 최신 `main` 브랜치와의 충돌을 최소화하기 위해 주기적으로 리베이스 또는 머지를 수행하는 것이 좋습니다.\\n\\n이와 같은 사항을 준수하면 효율적이고 체계적인 기능 개발과 코드 관리가 가능합니다.',\n",
       "  'role': 'assistant'},\n",
       " {'content': '릴리즈 노트 작성 시 체크리스트 알려줘.', 'role': 'user'},\n",
       " {'content': '<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"릴리즈 노트 작성 체크리스트\"}}</tool_call>',\n",
       "  'role': 'assistant'},\n",
       " {'content': '<tool_response>검색 결과:\\n-----\\n<!-- 회사: 코드노바 | 대상: 사원(프론트엔드) | 작성일: 2025-08-29 -->\\n# 프로젝트/제품 릴리즈 노트 관리 문서\\n분류: frontend | 회사: 코드노바 | 버전: v1.0 | 작성일: 2025-08-29\\n\\n---\\n\\n## 1. 릴리즈 노트 개요\\n\\n릴리즈 노트는 제품의 새로운 기능, 개선 사항, 버그 수정 및 기타 중요한 정보를 사용자와 팀원들에게 전달하는 문서입니다. 이 문서는 프론트엔드 팀이 프로젝트 또는 제품의 릴리즈를 관리하고 기록하는 데 도움을 줍니다.\\n\\n## 2. 릴리즈 노트 작성 단계\\n\\n### 2.1. 릴리즈 준비\\n\\n- [ ] 릴리즈 일정 확인\\n- [ ] 새로운 기능 및 수정 사항 목록 작성\\n- [ ] 관련 팀원에게 정보 요청 (디자인, 백엔드 등)\\n\\n### 2.2. 릴리즈 내용 정리 [[ref1]]\\n### 2.2. 릴리즈 내용 정리\\n\\n- [ ] 새로운 기능\\n  - 기능 설명: 각 기능에 대한 간단한 설명 및 사용 방법\\n  - 검증 포인트: 기능이 제대로 작동하는지 확인할 체크리스트\\n  \\n- [ ] 개선 사항\\n  - 개선 내용: 기존 기능의 개선 사항 설명\\n  - 검증 포인트: 개선된 기능이 예상대로 작동하는지 확인할 체크리스트\\n\\n- [ ] 버그 수정\\n  - 수정된 버그 목록: 수정된 버그의 설명 및 해결 방법\\n  - 검증 포인트: 수정된 버그가 재발생하지 않는지 확인할 체크리스트\\n\\n### 2.3. 릴리즈 노트 작성\\n\\n- [ ] 릴리즈 노트 템플릿 활용\\n  - 템플릿에 맞춰 작성하며, 각 항목에 대한 자세한 설명 추가\\n- [ ] 문서 검토\\n  - 팀원들과 함께 내용 검토 및 피드백 받기\\n  - 필요한 수정 사항 반영\\n\\n### 2.4. 릴리즈 노트 배포 [[ref2]]\\n### 2.4. 릴리즈 노트 배포\\n\\n- [ ] 내부 공유\\n  - 팀원들에게 릴리즈 노트 배포\\n  - 슬랙, 이메일 등으로 공유\\n- [ ] 외부 배포\\n  - 고객 및 사용자에게 릴리즈 노트 배포\\n  - 웹사이트, 블로그 등 적절한 채널 활용\\n\\n## 3. 릴리즈 노트 유지 관리\\n\\n- [ ] 릴리즈 노트에 대한 피드백 수집\\n  - 사용자 및 팀원들로부터 피드백 요청\\n- [ ] 정기적인 업데이트\\n  - 새로운 릴리즈가 있을 때마다 릴리즈 노트 업데이트\\n  - 이전 릴리즈 노트와의 연관성을 유지\\n\\n## 4. 검증 포인트\\n\\n- [ ] 릴리즈 노트 내용이 정확한지 확인\\n- [ ] 모든 기능 및 버그 수정이 검증되었는지 확인\\n- [ ] 릴리즈 노트가 적시에 배포되었는지 확인\\n\\n---\\n\\n다음 개정 제안: 릴리즈 노트 작성 시 팀원들의 피드백을 반영하기 위한 방법을 추가할 수 있습니다. 또한, 사용자 피드백을 수집하는 방법에 대한 구체적인 프로세스를 추가하는 것이 좋습니다. [[ref3]]\\n15. frontend - 프로젝트/제품 릴리즈 노트 관리 문서 -> 15_frontend__프로젝트_제품_릴리즈_노트_관리_문서.txt [[ref4]]\\n### 4.3 경고 체크리스트\\n\\n- [ ] 경고 기준이 명확히 설정되어 있는지 확인\\n- [ ] 알림 채널이 정상적으로 작동하는지 테스트\\n- [ ] 경고 발생 시 대응 프로세스가 마련되어 있는지 확인\\n\\n## 5. 정기 점검 및 리뷰\\n\\n- **정기 점검**: 로그 및 모니터링 설정을 정기적으로 점검하여 필요시 업데이트합니다.\\n- **리뷰 회의**: 주기적으로 팀 내 리뷰 회의를 개최하여 로그 및 모니터링 결과를 공유하고 개선 방안을 논의합니다.\\n\\n---\\n\\n이 가이드는 코드노바 프론트엔드 팀이 로그와 모니터링을 체계적으로 수행하는 데 도움이 될 것입니다. 각 팀원은 이 가이드를 참고하여 자신의 작업에 적용해 주시기 바랍니다.\\n\\n---\\n\\n**다음 개정 제안**: 로그 수집 도구에 대한 구체적인 사용 사례 추가 및 모니터링 지표의 중요도에 대한 설명을 보강할 필요가 있습니다. [[ref5]]\\n### 금요일\\n- **주간 회고 (10:00 - 11:00)**\\n  - 이번 주 진행한 업무에 대한 회고\\n  - 개선 사항 및 다음 주 계획 수립\\n- **자유 개발 시간 (11:00 - 17:00)**\\n  - 개인 프로젝트 또는 학습 시간\\n  - 새로운 기술 스택 및 도구 탐색\\n\\n## 3. 체크리스트\\n- [ ] 업무 회의에서 주간 목표 및 업무 확인\\n- [ ] UI/UX 개선 사항을 팀원과 공유\\n- [ ] 신규 기능 개발 요구사항 분석 완료\\n- [ ] 코드 리뷰 및 품질 관리 진행\\n- [ ] 버그 수정 사항 테스트 완료\\n- [ ] 기능 통합 및 테스트 완료\\n- [ ] 문서화 작업 완료\\n- [ ] 주간 회고 진행 및 피드백 수집 [[ref6]]\\n### 3.5 배포 단계\\n- **배포 준비**: 최종 검토 후 배포 계획 수립\\n- **검증 포인트**:\\n  - 배포가 원활하게 진행되었는가?\\n  - 사용자 피드백이 수집되었는가?\\n\\n## 4. 피드백 및 회고\\n- **정기 회의**: 프로젝트 종료 후 회고 회의 진행\\n- **검증 포인트**:\\n  - 무엇이 잘 되었고, 무엇이 개선되어야 하는가?\\n  - 다음 프로젝트에 반영할 수 있는 교훈은 무엇인가?\\n\\n## 5. 문서화\\n- **문서 작성**: 프로젝트 관련 문서 및 결과물 정리\\n- **검증 포인트**:\\n  - 모든 문서가 팀원에게 공유되었는가?\\n  - 문서가 쉽게 접근 가능하게 정리되었는가?\\n\\n---\\n\\n다음 개정 제안: 협업 도구의 업데이트 사항 및 새로운 역할이 추가될 경우 문서 개정 필요. [[ref7]]\\n<!-- 회사: 코드노바 | 대상: 사원(프론트엔드) | 작성일: 2025-08-29 -->\\n# 빌드/배포 가이드\\n분류: frontend | 회사: 코드노바 | 버전: v1.0 | 작성일: 2025-08-29\\n\\n---\\n\\n## 1. 빌드 준비\\n\\n### 1.1 환경 설정\\n- **Node.js 설치**: 최신 LTS 버전을 설치합니다.\\n- **패키지 매니저**: npm 또는 yarn을 설치합니다.\\n\\n### 1.2 프로젝트 클론\\n- GitHub에서 프로젝트를 클론합니다.\\n- `git clone [레포지토리 URL]` 명령어를 사용합니다.\\n\\n### 1.3 의존성 설치\\n- 프로젝트 디렉토리로 이동 후, 의존성을 설치합니다.\\n- `npm install` 또는 `yarn install` 명령어를 실행합니다.\\n\\n## 2. 빌드 프로세스\\n\\n### 2.1 빌드 명령어 실행\\n- 다음 명령어를 사용하여 빌드를 실행합니다.\\n- `npm run build` 또는 `yarn build` 명령어를 사용합니다. [[ref8]]</tool_response>',\n",
       "  'role': 'user'},\n",
       " {'content': '릴리즈 노트 작성 시 체크리스트는 다음과 같습니다.\\n\\n1. 릴리즈 준비\\n   - 릴리즈 일정 확인\\n   - 새로운 기능 및 수정 사항 목록 작성\\n   - 관련 팀원(디자인, 백엔드 등)에게 정보 요청\\n\\n2. 릴리즈 내용 정리\\n   - 새로운 기능: 기능 설명 및 검증 포인트 작성\\n   - 개선 사항: 개선 내용 및 검증 포인트 작성\\n   - 버그 수정: 수정된 버그 목록과 검증 포인트 작성\\n\\n3. 릴리즈 노트 작성\\n   - 템플릿에 맞춰 작성하고 각 항목에 대한 자세한 설명 추가\\n   - 팀원들과 내용 검토 및 피드백 반영\\n\\n4. 릴리즈 노트 배포\\n   - 내부 공유: 팀원들에게 배포 및 슬랙, 이메일 등으로 공유\\n   - 외부 배포: 고객 및 사용자에게 웹사이트, 블로그 등 적절한 채널로 배포\\n\\n5. 릴리즈 노트 유지 관리\\n   - 사용자 및 팀원으로부터 피드백 수집\\n   - 정기적으로 업데이트 및 이전 릴리즈 노트와 연관성 유지\\n\\n6. 검증 포인트\\n   - 릴리즈 노트 내용의 정확성 확인\\n   - 모든 기능 및 버그 수정 검증 여부 확인\\n   - 릴리즈 노트가 적시에 배포되었는지 확인\\n\\n이 체크리스트를 참고하여 체계적이고 정확한 릴리즈 노트를 작성하시기 바랍니다.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]['messages'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8232aa21-a500-4233-a596-210c0f030da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 데이터 분할 결과: Train 0개, Test 286개\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 포맷으로 변환 함수\n",
    "def format_conversations(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": sample['messages'][0]['content']},\n",
    "            *sample[\"messages\"][1:]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# 분할 및 변환\n",
    "train_dataset = [format_conversations(dataset[i]) for i in train_indices]\n",
    "test_dataset = [format_conversations(dataset[i]) for i in test_indices]\n",
    "\n",
    "# 리스트를 다시 HuggingFace Dataset 객체로 변환\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"\\n전체 데이터 분할 결과: Train {len(train_dataset)}개, Test {len(test_dataset)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7694c34-e788-4c6a-9164-c3b6790c23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chatml(data):\n",
    "    \"\"\"\n",
    "    data: messages 리스트이거나 {\"messages\": [...]} 형태의 dict\n",
    "    반환값: ChatML 포맷의 문자열\n",
    "    \"\"\"\n",
    "    # data가 dict이고 'messages' 키가 있으면 messages 리스트를 꺼내고,\n",
    "    # 아니면 data 자체를 messages 리스트로 간주\n",
    "    messages = data.get(\"messages\") if isinstance(data, dict) and \"messages\" in data else data\n",
    "\n",
    "    parts = []\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        parts.append(f\"<|im_start|>{role}\\n{content}<|im_end|>\")\n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0e4a70-bf27-4a1e-8b3e-b1d07ce71afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_examples(chatml: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    ChatML 문자열에서 각 assistant 응답을 분리하여\n",
    "    'input'과 'label' 쌍을 생성합니다.\n",
    "    'input'은 해당 assistant 응답 직전까지의 모든 대화 + '<|im_start|>assistant',\n",
    "    'label'은 해당 assistant의 응답 내용입니다.\n",
    "    \"\"\"\n",
    "    examples: List[Dict[str, str]] = []\n",
    "    pattern = re.compile(r'<\\|im_start\\|>assistant(.*?)(?=<\\|im_end\\|>)', re.DOTALL)\n",
    "\n",
    "    for match in pattern.finditer(chatml):\n",
    "        start_idx = match.start()\n",
    "        input_text = chatml[:start_idx].strip() + '\\n<|im_start|>assistant'\n",
    "        label_text = match.group(1).strip()\n",
    "        examples.append({\n",
    "            \"input\": input_text,\n",
    "            \"label\": label_text\n",
    "        })\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aee14ee-37d1-4294-bb59-933b3ed10d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for item in test_dataset:\n",
    "    chatml = to_chatml(item)  # ChatML 문자열로 변환\n",
    "    examples = extract_examples(chatml)  # assistant 응답 단위로 분리\n",
    "\n",
    "    for ex in examples:\n",
    "        prompt_lst.append(ex['input'])\n",
    "        label_lst.append(ex['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f8edaf-8f76-4055-b78a-c4db7548b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "당신은 사내 지식을 활용하여 사용자의 질문에 정확하고 유용한 답변을 제공하는 코드노바의 사내 문서 AI 챗봇입니다.\n",
      "\n",
      "\n",
      "사용자는 frontend(프론트엔드)팀에 속한 팀원입니다.\n",
      "당신은 <tools></tools> 안에 있는 tool을 호출하여 문서를 검색할 수 있습니다.\n",
      "일상적인 질문(ex: 안녕, 안녕하세요, 반가워 등)의 경우, tool 호출 없이 바로 답변하세요.\n",
      "\n",
      "# Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"frontend_search\", \"description\": \"사내 문서 검색을 위한 도구입니다. 대화 내역을 바탕으로 사용자가 원하는 문서를 찾고, 관련된 문서를 반환합니다.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"keyword\": {\"type\": \"string\", \"description\": \"검색할 문서 키워드 (예: '코드노바 API 서버 설정')\"}}, \"required\": [\"keyword\"], \"additionalProperties\": false}}}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>}'\n",
      "</tool_call>\n",
      "\n",
      "\n",
      "그리고 다음 지침을 반드시 따르세요:\n",
      "1. 기존의 말투는 잊고 정중하고 사무적인 어조로 답변해야 하세요.\n",
      "2. 대화 내역의 말투도 참고하지 말고 무조건 정중하고 사무적인 어조로 답변하세요\n",
      "3. 사실에 기반한 정보를 사용하세요.\n",
      "4. 사용자의 질문에 대한 답변을 문서에서 찾을 수 없을 경우, \"잘 모르겠습니다\"라고 솔직하게 말하세요.\n",
      "5. 사용자가 문서에 대한 질문이 아닌, \"안녕\"과 같은 일상적인 질문을 한다면 해당 내용에 대해서 적절히 답변해주세요.\n",
      "6. 답변이 너무 길지 않게 하세요.\n",
      "7. 사용자의 말투와 상관 없이, 반드시 정중하고 사무적인 어조로 답변해야 합니다.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "코드 리뷰 시 성능 및 보안 기준을 평가하는 구체적인 방법이나 체크리스트가 있다면 공유해 주실 수 있나요?<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    }
   ],
   "source": [
    "print(prompt_lst[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a2f2241-3929-431a-ae2f-6cd233b78ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"릴리즈 노트 작성 체크리스트\"}}</tool_call>\n"
     ]
    }
   ],
   "source": [
    "print(label_lst[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c41a7c-db21-4f33-840d-083a32978e02",
   "metadata": {},
   "source": [
    "## 2. 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e033a1-d9da-472c-9932-da800809469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    stop=[\"<|im_end|>\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb815432-e63a-4c67-a754-d1478a888dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-23 01:51:28 [utils.py:328] non-default args: {'disable_log_stats': True, 'model': 'SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66437661d8cf40dab96d207f4b1f430a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-23 01:51:42 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-23 01:51:42 [__init__.py:1815] Using max model len 40960\n",
      "INFO 09-23 01:51:44 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68367415fca14d80b8cbed02efbfca39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776e75bbf6ad44b5afb44ea9fc0067f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d9792f90f64a0d96e0e82095d17edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aef154ac9141a0808599ccf5999d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c0c9e52291430eb271f9499c417794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a650fa63c7124c01ba81c200a7382285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8322df2046b47e784c3dc5452761eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e50534228a42c6b83cbf520c92c12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:51:58 [core.py:654] Waiting for init message from front-end.\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:51:58 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19', speculative_config=None, tokenizer='SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:52:01 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m WARNING 09-23 01:52:01 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:52:01 [gpu_model_runner.py:2338] Starting to load model SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W923 01:52:01.828793177 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:52:01 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m WARNING 09-23 01:52:01 [cuda.py:349] FlashInfer failed to import for V1 engine on Blackwell (SM 10.0) GPUs; it is recommended to install FlashInfer for better performance.\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:52:01 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:52:01 [weight_utils.py:348] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba4bd95b13a4930822e1c776a568ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6f7e5dddac4e139570868ceeb4cd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2eb4563605645d3bc4fc96b4f840411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ccefacf16c4cde960f7adca513208e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:53:53 [weight_utils.py:369] Time spent downloading weights for SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19: 111.867800 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35725d9638749b0b25af4f0c1525578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cade49972714444b332ae935901d378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:53:55 [default_loader.py:268] Loading weights took 1.50 seconds\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:53:56 [gpu_model_runner.py:2392] Model loading took 15.2683 GiB and 114.341844 seconds\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:00 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/d625b601a4/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:00 [backends.py:550] Dynamo bytecode transform time: 3.50 s\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:02 [backends.py:194] Cache the graph for dynamic shape for later use\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:15 [backends.py:215] Compiling a graph for dynamic shape takes 15.03 s\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:16 [monitor.py:34] torch.compile takes 18.52 s in total\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:17 [gpu_worker.py:298] Available KV cache memory: 139.52 GiB\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:18 [kv_cache_utils.py:864] GPU KV cache size: 1,015,968 tokens\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:18 [kv_cache_utils.py:868] Maximum concurrency for 40,960 tokens per request: 24.80x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:01<00:00, 47.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:20 [gpu_model_runner.py:3118] Graph capturing finished in 2 secs, took 0.72 GiB\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:20 [gpu_worker.py:391] Free memory on device (177.65/178.35 GiB) on startup. Desired GPU memory utilization is (0.9, 160.52 GiB). Actual usage is 15.27 GiB for weight, 5.66 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.72 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=148879492608` to fit into requested memory, or `--kv-cache-memory=167277282816` to fully utilize gpu memory. Current kv cache memory in use is 149812725248 bytes.\n",
      "\u001B[1;36m(EngineCore_DP0 pid=1551)\u001B[0;0m INFO 09-23 01:54:20 [core.py:218] init engine (profile, create kv cache, warmup model) took 24.37 seconds\n",
      "INFO 09-23 01:54:21 [llm.py:295] Supported_tasks: ['generate']\n",
      "INFO 09-23 01:54:21 [__init__.py:36] No IOProcessor plugins requested by the model\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"SKN14-Final-1Team/qwen3-8b-informal-formal-merged-09-19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f8517f-70f3-4551-af7f-01c96b9afd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87e424c6830484db05c876d7cba59f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1b054886f04368b0983f063b09a697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/824 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tuned_outputs = llm.generate(prompt_lst, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "687732cb-f239-486e-92ce-c54dbc8ca4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_text_results = [sample.outputs[0].text.strip() for sample in fine_tuned_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4087696-f4c5-4ddc-ba7c-4256261ff6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"코드 리뷰 시 성능 평가 방법\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"코드 리뷰 시 보안 기준 평가 방법\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"코드 리뷰 체크리스트\"}}</tool_call>\n"
     ]
    }
   ],
   "source": [
    "print(fine_tuned_text_results[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045669a-e1b0-4953-bb09-db7ed7914dd4",
   "metadata": {},
   "source": [
    "## 3. 평가 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f91f23ee-c163-48b9-afd6-63f9b53375dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 예시 DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"prompt\": prompt_lst,\n",
    "    \"label\": label_lst,\n",
    "    \"output\": fine_tuned_text_results\n",
    "})\n",
    "\n",
    "# 'output' 컬럼에서 <think>...</think> 태그 제거\n",
    "df['output'] = df['output'].apply(lambda x: re.sub(r\"<think>.*?</think>\", \"\", x, flags=re.S))\n",
    "\n",
    "# 저장\n",
    "df.to_csv(\"evaluation_results.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0623b1d-e99e-4c12-a071-5b35896efffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"frontend_search\", \"argume...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"frontend_search\", \"argume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>프론트엔드 아키텍처 문서에 따르면, 성능 최적화를 위한 Lazy Loading은 필...</td>\n",
       "      <td>\\n\\n프론트엔드 아키텍처 문서에 따르면, 성능 최적화를 위한 Lazy Loadin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"frontend_search\", \"argume...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"frontend_search\", \"argume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>프론트엔드팀의 코드 리뷰 기준은 다음과 같습니다.\\n\\n- 모든 코드는 코드 리뷰를...</td>\n",
       "      <td>\\n\\n프론트엔드팀 코드 리뷰 기준은 다음과 같습니다.\\n\\n- 모든 코드는 코드 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"frontend_search\", \"argume...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"frontend_search\", \"argume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>주말에 방문할 만한 장소 추천에 관해서는 사내 문서에 관련 정보가 없어서 개인적인 ...</td>\n",
       "      <td>주말에 방문할 만한 장소 추천에 관해서는 사내 문서에 관련 정보가 없어서 구체적인 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>미안하지만, 나는 사내 문서 기반으로 정보를 주는 AI 챗봇이라 외부 최신 카페나 ...</td>\n",
       "      <td>미안하지만, 난 사내 문서 기반으로 업무 관련 정보만 알려주는 AI 챗봇이야. 카페...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>오늘 운동할 때 도움이 되는 기본 스트레칭 동작으로 '전신 스트레칭' 추천할게\\n\\...</td>\n",
       "      <td>\\n\\n운동할 때 도움 되는 간단한 스트레칭 동작으로 '목 돌리기' 추천할게.\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"cto_search\", \"arguments\":...</td>\n",
       "      <td>&lt;tool_call&gt;{\"name\": \"cto_search\", \"arguments\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>&lt;|im_start|&gt;system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...</td>\n",
       "      <td>CTO 업무 인수인계랑 관련된 구체적인 문서는 검색 결과에 포함되어 있지 않아. 대...</td>\n",
       "      <td>\\n\\nCTO 업무 인수인계 관련 문서로는 \"주요 인사(승진·이동·해고) 관리 문서...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "1    <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "2    <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "3    <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "4    <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "..                                                 ...   \n",
       "819  <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "820  <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "821  <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "822  <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "823  <|im_start|>system\\n\\n당신은 사내 지식을 활용하여 사용자의 질문에...   \n",
       "\n",
       "                                                 label  \\\n",
       "0    <tool_call>{\"name\": \"frontend_search\", \"argume...   \n",
       "1    프론트엔드 아키텍처 문서에 따르면, 성능 최적화를 위한 Lazy Loading은 필...   \n",
       "2    <tool_call>{\"name\": \"frontend_search\", \"argume...   \n",
       "3    프론트엔드팀의 코드 리뷰 기준은 다음과 같습니다.\\n\\n- 모든 코드는 코드 리뷰를...   \n",
       "4    <tool_call>{\"name\": \"frontend_search\", \"argume...   \n",
       "..                                                 ...   \n",
       "819  주말에 방문할 만한 장소 추천에 관해서는 사내 문서에 관련 정보가 없어서 개인적인 ...   \n",
       "820  미안하지만, 나는 사내 문서 기반으로 정보를 주는 AI 챗봇이라 외부 최신 카페나 ...   \n",
       "821  오늘 운동할 때 도움이 되는 기본 스트레칭 동작으로 '전신 스트레칭' 추천할게\\n\\...   \n",
       "822  <tool_call>{\"name\": \"cto_search\", \"arguments\":...   \n",
       "823  CTO 업무 인수인계랑 관련된 구체적인 문서는 검색 결과에 포함되어 있지 않아. 대...   \n",
       "\n",
       "                                                output  \n",
       "0    <tool_call>{\"name\": \"frontend_search\", \"argume...  \n",
       "1    \\n\\n프론트엔드 아키텍처 문서에 따르면, 성능 최적화를 위한 Lazy Loadin...  \n",
       "2    <tool_call>{\"name\": \"frontend_search\", \"argume...  \n",
       "3    \\n\\n프론트엔드팀 코드 리뷰 기준은 다음과 같습니다.\\n\\n- 모든 코드는 코드 ...  \n",
       "4    <tool_call>{\"name\": \"frontend_search\", \"argume...  \n",
       "..                                                 ...  \n",
       "819  주말에 방문할 만한 장소 추천에 관해서는 사내 문서에 관련 정보가 없어서 구체적인 ...  \n",
       "820  미안하지만, 난 사내 문서 기반으로 업무 관련 정보만 알려주는 AI 챗봇이야. 카페...  \n",
       "821  \\n\\n운동할 때 도움 되는 간단한 스트레칭 동작으로 '목 돌리기' 추천할게.\\n\\...  \n",
       "822  <tool_call>{\"name\": \"cto_search\", \"arguments\":...  \n",
       "823  \\n\\nCTO 업무 인수인계 관련 문서로는 \"주요 인사(승진·이동·해고) 관리 문서...  \n",
       "\n",
       "[824 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbddd043-c1fd-43ab-a724-e61c1b7215fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드/배포 가이드의 1.1 환경 설정에서 Node.js 설치에 대한 구체적인 버전 요구사항\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드/배포 가이드의 1.1 환경 설정에서 Node.js 설치에 대한 구체적인 버전 요구사항\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 빌드/배포 가이드의 '1.1 환경 설정' 파트에 따르면, Node.js는 최신 LTS(Long Term Support) 버전을 설치해야 합니다. 구체적인 버전 번호보다는 최신 LTS 버전을 사용하는 것이 요구사항입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "빌드/배포 가이드의 '1.1 환경 설정' 파트에 따르면, Node.js는 최신 LTS(LTS) 버전을 설치하는 것이 요구사항입니다. 구체적인 버전 번호는 명시되어 있지 않으나, 최신 LTS 버전을 권장하고 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : 오늘 저녁 메뉴로는 건강과 균형을 고려하여 단백질과 채소가 풍부한 그릴드 치킨 샐러드나 연어 스테이크를 추천드립니다. 간단하면서도 영양가 있는 식사를 원하신다면 이 메뉴가 적합할 것입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "오늘 저녁 메뉴로는 균형 잡힌 영양과 맛을 고려하여 닭가슴살 샐러드나 구운 닭고기, 그리고 신선한 채소와 함께하는 샐러드를 추천드립니다. 건강에도 좋고 소화도 잘 되는 메뉴입니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드/배포 가이드의 1.2 프로젝트 클론에서 GitHub에서 프로젝트를 클론할 때 사용하는 명령어\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드/배포 가이드의 1.2 프로젝트 클론 파트에서 GitHub 프로젝트 클론 명령어\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 빌드/배포 가이드의 '1.2 프로젝트 클론' 파트에 따르면, GitHub에서 프로젝트를 클론할 때 사용하는 명령어는 다음과 같습니다.\n",
      "\n",
      "```\n",
      "git clone [레포지토리 URL]\n",
      "```\n",
      "\n",
      "위 명령어에서 [레포지토리 URL] 부분에 해당 프로젝트의 GitHub 저장소 URL을 입력하여 사용하시면 됩니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "빌드/배포 가이드의 '1.2 프로젝트 클론' 파트에서 GitHub에서 프로젝트를 클론할 때 사용하는 명령어는 `git clone [레포지토리 URL]`입니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"의존성 설치 방법\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"의존성 설치 방법\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 의존성 설치 방법은 다음과 같습니다.\n",
      "\n",
      "프로젝트 디렉토리로 이동한 후, 아래 명령어 중 하나를 실행하여 의존성을 설치합니다.\n",
      "\n",
      "```\n",
      "npm install\n",
      "```\n",
      "또는\n",
      "```\n",
      "yarn install\n",
      "```\n",
      "\n",
      "위 명령어를 통해 프로젝트에 필요한 패키지들이 설치됩니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "프로젝트 디렉토리로 이동한 후, 의존성을 설치하는 방법은 다음과 같습니다.\n",
      "\n",
      "- npm을 사용하는 경우: `npm install` 명령어를 실행합니다.\n",
      "- yarn을 사용하는 경우: `yarn install` 명령어를 실행합니다.\n",
      "\n",
      "이 두 명령어를 통해 프로젝트에 필요한 의존성을 설치할 수 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드/배포 가이드 의존성 설치 명령어\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드/배포 가이드 의존성 설치 명령어\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 빌드/배포 가이드의 '1.3 의존성 설치' 파트에서는 프로젝트 디렉토리로 이동한 후 다음 명령어를 실행하여 의존성을 설치합니다.\n",
      "\n",
      "- `npm install` 또는 `yarn install`\n",
      "\n",
      "이 명령어를 통해 필요한 패키지들이 설치됩니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "빌드/배포 가이드의 '1.3 의존성 설치' 파트에서 의존성을 설치하기 위해 실행해야 하는 명령어는 다음과 같습니다.\n",
      "\n",
      "- 프로젝트 디렉토리로 이동한 후, 다음 명령어 중 하나를 실행합니다.\n",
      "  - `npm install`\n",
      "  - `yarn install`\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드 명령어\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"빌드 명령어\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 빌드 명령어는 다음과 같습니다.\n",
      "\n",
      "- `npm run build` 또는 `yarn build`\n",
      "\n",
      "이 명령어를 사용하여 프로젝트를 빌드할 수 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "빌드 명령어는 다음과 같습니다.\n",
      "\n",
      "- `npm run build` 또는 `yarn build`\n",
      "\n",
      "이 명령어를 실행하면 프로젝트를 빌드할 수 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : 오늘 날씨가 흐리다면 우산을 챙기시는 것을 권장드립니다. 비가 올 가능성에 대비하여 준비하시는 것이 좋습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "오늘 날씨가 흐리다고 하셨군요. 우산을 챙기시는 것을 권장드립니다. 비가 올 가능성에 대비하여 준비하시면 좋겠습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"배포 서버 설정 방법\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"배포 서버 설정 방법\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 배포 서버 설정 방법은 다음과 같습니다.\n",
      "\n",
      "1. 배포할 서버에 접근합니다. 필요 시 SSH로 접속합니다.\n",
      "2. 빌드된 파일을 서버로 전송합니다. `scp` 또는 FTP 클라이언트를 사용할 수 있습니다.\n",
      "3. 웹 서버(Nginx, Apache 등)의 설정 파일을 수정합니다.\n",
      "4. 필요한 경우 SSL 인증서 설정을 확인합니다.\n",
      "5. 웹 서버를 재시작하여 변경 사항을 적용합니다. 예: `sudo systemctl restart [웹 서버 이름]`\n",
      "6. 브라우저에서 배포된 URL을 열어 정상 작동 여부를 확인합니다.\n",
      "7. 서버 로그(`/var/log/[웹 서버 이름]/error.log`)를 확인하여 오류를 점검합니다.\n",
      "\n",
      "이 과정을 통해 배포 서버를 설정할 수 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "배포 서버 설정 방법은 다음과 같습니다.\n",
      "\n",
      "1. 배포할 서버에 접근합니다.\n",
      "2. 필요 시 SSH를 통해 서버에 접속합니다.\n",
      "3. 빌드된 파일을 서버에 전송합니다. 이는 `scp` 명령어나 FTP 클라이언트를 사용하여 수행합니다.\n",
      "4. 웹 서버(Nginx, Apache 등)의 설정 파일을 수정합니다.\n",
      "5. 필요 시 SSL 인증서 설정을 확인합니다.\n",
      "6. 웹 서버를 재시작하여 변경 사항을 적용합니다. 예를 들어, `sudo systemctl restart [웹 서버 이름]` 명령어를 사용합니다.\n",
      "7. 배포된 URL을 브라우저로 열어 정상 작동하는지 확인합니다.\n",
      "\n",
      "이 과정을 통해 배포 서버를 설정할 수 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 및 상호작용 요소 섹션의 상태 표시 구체적인 예시\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 및 상호작용 요소 섹션의 상태 표시 구체적인 예시\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 버튼 및 상호작용 요소 섹션에서 상태 표시의 구체적인 예시는 다음과 같습니다.\n",
      "\n",
      "- 버튼 클릭 후 로딩 상태를 명확히 표시하여 사용자가 작업 진행 중임을 알 수 있도록 합니다.\n",
      "- 비활성 상태를 표시하여 현재 버튼이 클릭 불가능함을 시각적으로 구분합니다.\n",
      "\n",
      "이와 같은 상태 표시는 사용자에게 명확한 피드백을 제공하는 데 중요한 역할을 합니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "버튼 및 상호작용 요소 섹션에서 상태 표시의 구체적인 예시로는 버튼 클릭 후 로딩 상태나 비활성 상태를 명확히 표시하는 것이 있습니다. 이는 사용자에게 명확한 피드백을 제공하여 상호작용의 진행 상황을 알 수 있도록 합니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 상태 표시와 관련된 컴포넌트 작성 시 상태(state)와 속성(props) 구분 및 관리 방법\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 상태 표시와 관련된 컴포넌트 작성 시 상태(state)와 속성(props) 구분 방법\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 버튼 상태 표시와 관련된 컴포넌트 작성 시 상태(state)와 속성(props)은 다음과 같이 구분하여 관리해야 합니다.\n",
      "\n",
      "- 상태(state)는 컴포넌트 내부에서 변경될 수 있는 데이터로, 예를 들어 버튼의 로딩 상태나 활성/비활성 상태와 같이 컴포넌트 자체가 관리하는 동적인 값을 의미합니다.\n",
      "- 속성(props)은 부모 컴포넌트로부터 전달받는 값으로, 컴포넌트의 동작이나 표시를 제어하는 외부 입력값입니다. 예를 들어 버튼의 텍스트, 스타일 종류, 클릭 이벤트 핸들러 등이 이에 해당합니다.\n",
      "\n",
      "이처럼 상태와 속성을 명확히 구분하여 관리하면 컴포넌트의 재사용성과 유지보수성이 향상됩니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "버튼 상태 표시와 관련된 컴포넌트 작성 시, 상태(state)와 속성(props)은 다음과 같이 명확히 구분하여 관리해야 합니다.\n",
      "\n",
      "- 상태(state): 컴포넌트 내부에서 관리하는 데이터로, 버튼의 현재 상태(예: 활성, 비활성, 로딩 중)를 나타냅니다. 상태 변경은 컴포넌트 내부 로직에서 처리하며, 상태에 따라 UI가 동적으로 변경됩니다.\n",
      "- 속성(props): 부모 컴포넌트에서 전달하는 데이터로, 버튼의 기본 내용이나 외부 상태를 전달받습니다. 예를 들어 버튼 텍스트, 아이콘, 클릭 시 동작을 정의하는 값들이 속성으로 전달됩니다.\n",
      "\n",
      "이와 같이 상태는 컴포넌트 내부 상태 관리에 사용하고, 속성은 외부에서 전달받는 데이터로 구분하여 관리하는 것이 좋습니다. 이를 통해 컴포넌트의 역할과 책임을 명확히 하고, 재사용성과 가독성을 높일 수 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 컴포넌트의 상태(state)와 속성(props) 구분 및 관리 방법\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 컴포넌트의 유닛 테스트 및 통합 테스트 작성 시 검증해야 할 부분\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 컴포넌트의 상태(state)와 속성(props) 관리 시 유닛 테스트 검증 포인트\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"버튼 컴포넌트의 상태(state)와 속성(props) 관리 시 통합 테스트 검증 포인트\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 버튼 컴포넌트의 상태(state)와 속성(props)을 구분하여 관리할 때, 테스트 작성 시 중점적으로 검증해야 할 사항은 다음과 같습니다.\n",
      "\n",
      "1. 유닛 테스트\n",
      "- 상태(state): 버튼의 로딩, 활성/비활성 상태 등 내부 상태 변화가 올바르게 반영되는지 검증합니다.\n",
      "- 속성(props): 부모 컴포넌트로부터 전달받는 텍스트, 스타일, 이벤트 핸들러 등이 정상적으로 적용되는지 확인합니다.\n",
      "\n",
      "2. 통합 테스트\n",
      "- 여러 컴포넌트가 함께 작동할 때 버튼 상태 변화가 전체 UI 흐름에 적절히 반영되는지 검증합니다.\n",
      "- 버튼 클릭 시 API 호출이나 다른 컴포넌트와의 상호작용이 정상적으로 이루어지는지 확인합니다.\n",
      "\n",
      "이와 같이 유닛 테스트는 개별 컴포넌트의 기능과 상태 관리에 집중하고, 통합 테스트는 컴포넌트 간 상호작용과 전체 동작 흐름을 검증하는 데 중점을 둡니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "버튼 컴포넌트의 유닛 테스트와 통합 테스트 작성 시 검증해야 할 부분은 다음과 같습니다.\n",
      "\n",
      "1. 유닛 테스트(Unit Testing)\n",
      "- 버튼 컴포넌트 내부 상태(state)가 올바르게 초기화되는지 확인\n",
      "- 클릭 이벤트, 호버 효과, 로딩 상태, 비활성 상태 등 주요 동작이 제대로 동작하는지 검증\n",
      "- props를 통해 전달받은 값이 컴포넌트에 정확히 반영되는지 점검\n",
      "- 예외 상황(예: null 값, 잘못된 속성 전달)에 대한 처리가 적절한지 확인\n",
      "\n",
      "2. 통합 테스트(Integration Testing)\n",
      "- 버튼 컴포넌트가 부모 컴포넌트와 상호작용할 때 데이터 흐름이 제대로 이루어지는지 검증\n",
      "- API 호출이나 상태 변경과 연동되는 동작이 제대로 동작하는지 확인\n",
      "- 여러 컴포넌트가 함께 작동할 때 버튼 상태 표시가 일관되게 반영되는지 점검\n",
      "\n",
      "이와 같이 유닛 테스트는 컴포넌트 내부 로직과 상태 관리에 집중하고, 통합 테스트는 컴포넌트 간 상호작용과 전체 흐름을 검증하는 방식으로 진행하는 것이 권장됩니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"레이아웃 및 그리드 시스템 여백 설정 기준\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"레이아웃 및 그리드 시스템 패딩 설정 기준\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"레이아웃 및 그리드 시스템의 여백 설정 기준\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"레이아웃 및 그리드 시스템의 패딩 설정 기준\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 레이아웃 및 그리드 시스템 섹션에서 여백 및 패딩 설정의 기준은 다음과 같습니다.\n",
      "\n",
      "- 12열 그리드 시스템을 기본으로 사용하여 일관된 레이아웃을 유지합니다.\n",
      "- 요소 간의 여백과 패딩을 적절히 설정하여 시각적으로 쾌적한 공간을 만듭니다.\n",
      "- 반복적으로 사용되는 UI 요소는 모듈화하여 재사용할 수 있도록 설계합니다.\n",
      "\n",
      "즉, 여백과 패딩은 그리드 시스템 내에서 시각적 쾌적함과 일관성을 유지할 수 있도록 적절히 조절하는 것이 기준입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "레이아웃 및 그리드 시스템 섹션에서 여백 및 패딩 설정의 기준은 요소 간의 여백과 패딩을 적절히 설정하여 시각적으로 쾌적한 공간을 만들어야 한다는 것입니다. 또한, 12열 그리드 시스템을 기본으로 사용하여 일관된 레이아웃을 유지하는 것이 권장됩니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"UI/UX 디자인 가이드라인 레이아웃 및 그리드 시스템 예시 사례\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"UI/UX 디자인 가이드라인 레이아웃 및 그리드 시스템 예시\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 현재 UI/UX 디자인 가이드라인 문서에는 레이아웃 및 그리드 시스템 섹션에 구체적인 예시 사례가 포함되어 있지 않습니다. 다만, 각 섹션에 예시를 추가하여 이해를 돕고 최신 트렌드를 반영하는 업데이트가 제안된 상태입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "현재 문서 내에는 레이아웃 및 그리드 시스템 섹션에 구체적인 예시 사례가 포함되어 있지 않습니다. 다만, 12열 그리드 시스템을 기본으로 사용하고, 요소 간의 여백과 패딩을 적절히 설정하여 시각적으로 쾌적한 공간을 만드는 내용만 명시되어 있습니다. 따라서, 구체적인 예시 사례는 추가되어 있지 않은 것으로 확인됩니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"이미지 및 아이콘 사용 섹션\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"아이콘 스타일 일관성 유지 방법\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"아이콘 스타일 일관성 유지 방법\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 이미지 및 아이콘 사용 섹션에서는 아이콘 스타일의 일관성을 유지하기 위해 다음과 같은 원칙을 따릅니다.\n",
      "\n",
      "- 일관된 스타일의 아이콘을 사용하여 UI의 통일성을 유지합니다.\n",
      "- 아이콘은 직관적이어야 하며, 사용자에게 명확한 의미를 전달해야 합니다.\n",
      "\n",
      "이를 통해 전체 UI 디자인의 통일성과 사용자 경험의 명확성을 확보할 수 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "이미지 및 아이콘 사용 섹션에서 아이콘 스타일의 일관성을 유지하는 방법은 다음과 같습니다.\n",
      "\n",
      "- 일관된 스타일의 아이콘을 사용하여 UI의 통일성을 유지합니다.\n",
      "- 아이콘은 직관적이어야 하며, 사용자에게 명확한 의미를 전달해야 합니다.\n",
      "- 고해상도의 이미지를 사용하고, 관련성이 높은 이미지를 선택하여 콘텐츠와의 연관성을 높입니다.\n",
      "\n",
      "이와 함께 디자인 시스템을 문서화하고 버전 관리를 통해 스타일 변경 사항을 체계적으로 관리하는 것도 중요합니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"사용자 피드백 섹션의 테스트 절차\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"사용자 피드백 섹션의 검증 절차\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"사용자 피드백 섹션의 테스트 절차\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"사용자 피드백 섹션의 검증 절차\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 사용자 피드백 섹션에서 테스트 및 검증 절차는 다음과 같이 진행됩니다.\n",
      "\n",
      "1. 테스트 계획 수립\n",
      "   - 테스트 범위 정의 및 환경 설정\n",
      "   - 테스트 일정 수립\n",
      "\n",
      "2. 테스트 케이스 작성 및 리뷰\n",
      "   - 각 기능별 테스트 케이스 작성\n",
      "   - 동료 리뷰를 통한 누락 사항 점검\n",
      "   - 우선순위 설정\n",
      "\n",
      "3. 테스트 실행\n",
      "   - 작성된 테스트 케이스에 따라 테스트 수행\n",
      "   - 결과 기록 및 버그 보고\n",
      "\n",
      "4. 테스트 결과 분석\n",
      "   - 문제점 도출 및 개선 사항 정리\n",
      "   - 팀원들과 결과 및 개선 사항 공유\n",
      "\n",
      "5. 검증 포인트 확인\n",
      "   - UI/UX 개선 사항이 사용자 피드백을 반영했는지 확인\n",
      "   - 신규 기능이 요구사항에 부합하는지 검토\n",
      "   - 코드 품질 향상 및 버그 수정 후 기존 기능 영향 여부 테스트\n",
      "   - 문서화 완료 및 팀원 접근성 확인\n",
      "\n",
      "6. 사용자 피드백 수집 및 반영\n",
      "   - 사용자 피드백을 수집하여 개선점 도출\n",
      "   - 피드백을 바탕으로 UI/UX 개선 작업 진행\n",
      "   - 정기적인 피드백 회의를 통해 개선 사항 공유 및 우선순위 결정\n",
      "\n",
      "이 절차를 통해 사용자 피드백을 체계적으로 테스트하고 검증하며, 지속적인 품질 향상을 도모합니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "사용자 피드백 섹션에서 테스트 및 검증 절차는 다음과 같습니다.\n",
      "\n",
      "1. 테스트 계획 수립: 테스트 범위와 환경 설정, 일정을 정합니다.\n",
      "2. 테스트 케이스 작성 및 리뷰: 각 기능에 대한 테스트 케이스를 작성하고 리뷰합니다.\n",
      "3. 테스트 실행: 작성된 테스트 케이스를 실행하고 결과를 기록합니다.\n",
      "4. 테스트 결과 분석: 문제점 도출하고 개선 사항을 정리하며 팀원과 공유합니다.\n",
      "5. 회귀 테스트: 새로운 기능 추가 또는 버그 수정 후 기존 기능이 정상 작동하는지 확인합니다.\n",
      "6. 검증 포인트 확인: UI/UX 개선 사항이 사용자 피드백을 반영했는지, 신규 기능이 요구사항에 부합하는지, 코드 품질과 기존 기능에 영향이 없는지, 문서화가 완료되었는지 등을 검토합니다.\n",
      "7. 배포 후 검증: 배포가 원활하게 진행되었는지, 사용자 피드백이 수집되었는지 확인합니다.\n",
      "8. 피드백 및 회고: 정기 회의를 통해 잘된 점과 개선 사항을 논의하고, 문서화하여 팀원과 공유합니다.\n",
      "\n",
      "이 절차를 통해 체계적으로 테스트하고 검증하며, 사용자 피드백을 반영하여 지속적인 개선을 도모합니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"프론트엔드 아키텍처 문서의 각 페이지에 해당하는 컴포넌트 폴더 위치\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"프론트엔드 아키텍처 문서에서 각 페이지에 해당하는 컴포넌트 폴더 위치\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 프론트엔드 아키텍처 문서에서 각 페이지에 해당하는 컴포넌트가 위치하는 폴더에 대한 구체적인 내용은 문서에서 확인되지 않습니다. 추가로 필요한 정보가 있으시면 알려주시면 도움을 드리겠습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "프론트엔드 아키텍처 문서 내에서 각 페이지에 해당하는 컴포넌트의 폴더 위치에 대한 구체적인 설명은 문서에 명시되어 있지 않습니다. 추가로 필요한 정보가 있으시면 알려주시면 도움을 드리겠습니다.\n",
      "====================================================================================================\n",
      "레이블 : 오늘 운동으로는 유산소 운동과 근력 운동을 적절히 조합하는 것을 추천드립니다. 예를 들어, 가벼운 조깅이나 빠른 걷기로 시작하여 심박수를 올린 후, 스쿼트, 푸시업, 플랭크 같은 근력 운동을 하시면 전신을 효과적으로 단련할 수 있습니다. 운동 전후에는 충분한 스트레칭으로 부상을 예방하시기 바랍니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "오늘 운동으로는 유산소 운동과 근력 운동을 조합하는 것이 좋습니다. 예를 들어, 조깅이나 달리기로 체력과 심폐 기능을 향상시키고, 스쿼트나 플랭크 같은 근력 운동으로 체력과 균형을 강화할 수 있습니다. 개인의 체력과 목표에 맞게 적절히 조절하시면 효과적일 것입니다.\n",
      "====================================================================================================\n",
      "레이블 : 오늘 저녁 메뉴로는 균형 잡힌 영양과 소화를 고려하여 닭가슴살 샐러드를 추천드립니다. 단백질과 신선한 채소가 조화를 이루어 건강에 좋고 부담 없이 즐기실 수 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "오늘 저녁 메뉴로는 균형 잡힌 영양과 맛을 고려하여 닭가슴살 샐러드와 함께 구운 채소를 추천드립니다. 단백질과 비타민이 풍부하여 건강에 좋고, 가벼운 식사로도 적합합니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"프론트엔드 아키텍처 문서의 결론 부분에서 강조하는 개발자의 생산성을 높이기 위한 원칙\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"프론트엔드 아키텍처 문서 결론의 개발자 생산성 향상 원칙\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 프론트엔드 아키텍처 문서의 결론 부분에서는 코드노바의 프론트엔드 아키텍처가 사용자 경험을 최우선으로 하며, 개발자의 생산성을 높이기 위해 설계되었음을 강조하고 있습니다. 따라서 위의 원칙과 프로세스를 준수하여 개발에 임할 것을 권고하고 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "프론트엔드 아키텍처 문서의 결론 부분에서는 개발자의 생산성을 높이기 위해 위의 원칙과 프로세스를 준수하여 개발에 임하라고 강조하고 있습니다. 구체적인 원칙은 문서 내에서 명시되어 있지 않으나, 사용자 경험을 최우선으로 하며 체계적인 아키텍처 설계와 프로세스 준수를 통해 생산성을 높이는 것이 핵심입니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"프론트엔드팀 회의록 #2 액션 아이템\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"프론트엔드팀 회의록 정기회의 #2 액션 아이템\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 프론트엔드팀 정기회의 #2에서 결정된 액션 아이템은 다음과 같습니다.\n",
      "\n",
      "1. 정기적인 피드백 세션에 팀원들이 참여하여 자신의 작업에 대한 의견을 듣는 것\n",
      "2. 팀의 프로세스나 도구에 대한 개선 사항을 제안하는 것\n",
      "\n",
      "이 두 가지가 주요 액션 아이템으로 논의되었습니다. 추가로, 현재 진행 중인 프로젝트는 예정대로 진행 중이며, UI/UX 테스트 단계에 사용자 피드백을 반영할 준비가 되어 있다는 점도 확인되었습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "프론트엔드팀 정기회의 #2에서 결정된 액션 아이템은 다음과 같습니다.\n",
      "\n",
      "- 이영희 님이 맡고 있는 기능 개발은 UI/UX 테스트 단계에 있으며, 사용자 피드백을 반영할 준비가 되어 있음.\n",
      "- 정기적인 피드백 세션 참여 및 팀 프로세스나 도구에 대한 개선 사항 제안.\n",
      "\n",
      "구체적인 액션 아이템으로는 사용자 피드백 반영 준비 및 정기 피드백 세션 참여가 포함되어 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : 오늘 운동하실 때 추천드리는 스트레칭 동작은 '고양이-소 자세 스트레칭'입니다. \n",
      "\n",
      "방법은 다음과 같습니다:\n",
      "1. 네 발로 기기 자세를 취합니다(손은 어깨 아래, 무릎은 엉덩이 아래 위치).\n",
      "2. 숨을 들이마시면서 등을 아래로 내리고 머리와 엉덩이를 들어 올려 '소 자세'를 만듭니다.\n",
      "3. 숨을 내쉬면서 등을 둥글게 말아 올리고 머리를 아래로 숙여 '고양이 자세'를 만듭니다.\n",
      "4. 이 동작을 천천히 5~10회 반복합니다.\n",
      "\n",
      "이 스트레칭은 척추를 부드럽게 움직여 긴장을 풀어주고, 허리와 목의 유연성을 높이는 데 도움이 됩니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "오늘 운동할 만한 간단한 스트레칭 동작으로 '목 돌리기'를 추천드립니다.\n",
      "\n",
      "1. 편안하게 앉거나 서서 어깨를 편안하게 내립니다.\n",
      "2. 천천히 목을 오른쪽으로 돌려서 어깨 너머를 바라봅니다.\n",
      "3. 5초간 유지한 후, 천천히 원위치로 돌아옵니다.\n",
      "4. 같은 방법으로 왼쪽도 반복합니다.\n",
      "5. 이 동작을 3~5회 반복하세요.\n",
      "\n",
      "목 근육을 부드럽게 풀어주고, 긴장 완화에 도움이 됩니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"최근 실패 사례\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"최근 실패 사례에 대한 대응 기록\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"실패 사례\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"대응 기록\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"Postmortem 문서\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 가장 최근 실패 사례는 2025년 8월 15일에 발생한 \"코드노바 웹 애플리케이션 업데이트\" 관련 사건입니다. 새로운 기능 배포 후 사용자 인터페이스(UI)에서 심각한 버그가 발생하여 일부 사용자가 기능을 사용할 수 없는 상황이었습니다.\n",
      "\n",
      "이에 대한 대응으로 즉각적으로 문제 발생 후 1시간 이내 긴급 회의를 소집하고, 버그 수정 패치를 배포하였으며 사용자에게 공지사항과 사과 메시지를 전달하였습니다. 장기적으로는 테스트 자동화 도구 도입, 코드 리뷰 프로세스 강화, QA팀과의 정기 협업 미팅 일정을 수립하는 조치를 취하였습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "최근 실패 사례는 2025년 8월 15일에 발생한 코드노바 웹 애플리케이션 업데이트 관련 심각한 UI 버그입니다. 이는 새로운 라이브러리 도입으로 인한 호환성 문제와 충분한 테스트 진행 부족, 코드 리뷰 절차 미흡, QA팀과의 협업 부족 등 여러 원인이 복합적으로 작용한 결과입니다.\n",
      "\n",
      "대응 조치로는 문제 발생 후 1시간 이내 긴급 회의를 소집하여 버그 수정 패치를 배포하고, 사용자에게 공지사항과 사과 메시지를 전달하였습니다. 장기적으로는 테스트 자동화 도구 도입, 코드 리뷰 프로세스 강화, QA팀과의 정기 협업 미팅 일정 수립 등이 이루어졌습니다. 또한, 사용자 피드백 회의 일정 설정, 버그 수정 및 개선 사항 완료, 신규 기능 우선순위 리스트 작성 등의 후속 조치가 진행 중입니다.\n",
      "====================================================================================================\n",
      "레이블 : 오늘 간단하게 할 수 있는 스트레칭 동작으로 목 돌리기를 추천드립니다. \n",
      "\n",
      "1. 편안하게 앉거나 서서 어깨를 편안하게 내립니다.\n",
      "2. 천천히 목을 오른쪽으로 돌려서 어깨 너머를 바라봅니다.\n",
      "3. 5초간 유지한 후, 천천히 원위치로 돌아옵니다.\n",
      "4. 같은 방법으로 왼쪽도 반복합니다.\n",
      "5. 이 동작을 3~5회 반복하세요.\n",
      "\n",
      "목 근육 긴장을 완화하고 혈액순환에 도움이 됩니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: 간단하게 할 수 있는 스트레칭 동작으로 \"목 돌리기\"를 추천드립니다.\n",
      "\n",
      "방법은 다음과 같습니다:\n",
      "1. 편안하게 앉거나 서서 어깨를 편안하게 내립니다.\n",
      "2. 천천히 목을 오른쪽으로 돌려서 어깨 너머를 바라봅니다.\n",
      "3. 5초간 유지한 후, 천천히 원위치로 돌아옵니다.\n",
      "4. 같은 방법으로 왼쪽도 반복합니다.\n",
      "5. 총 3~5회 반복하세요.\n",
      "\n",
      "이 동작은 목과 어깨의 긴장을 풀어주고 혈액 순환을 도와줍니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"크로스사이트 스크립팅(XSS) 방지 지침\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"입력 검증의 중요성\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"크로스사이트 스크립팅 방지 지침\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"입력 검증의 중요성\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 크로스사이트 스크립팅(XSS) 방지 섹션에서는 사용자 입력에 대해 반드시 유효성 검증과 필터링을 적용해야 한다고 지침을 제시하고 있습니다. 이는 악성 스크립트가 입력되는 것을 방지하기 위한 기본적인 보안 조치입니다. 또한, HTML, CSS, JavaScript에 출력되는 데이터는 항상 인코딩하여 XSS 공격을 예방해야 한다고 명시되어 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "크로스사이트 스크립팅(XSS) 방지 섹션에서는 사용자 입력을 받을 경우 반드시 유효성을 검증하고 필터링을 적용해야 한다고 명시하고 있습니다. 입력 검증은 XSS 공격을 방지하기 위한 필수적인 절차이며, 이를 통해 악성 스크립트가 실행되는 것을 차단할 수 있습니다. 또한, 출력 시에는 HTML, CSS, JavaScript에 출력되는 데이터를 항상 인코딩하여 XSS 위험을 최소화하는 지침이 제시되어 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"크로스사이트 요청 위조(CSRF) 방지\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"CSRF 토큰 사용에 대한 구체적인 요구사항\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"크로스사이트 요청 위조(CSRF) 방지에 대한 CSRF 토큰 사용 요구사항\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 크로스사이트 요청 위조(CSRF) 방지 파트에서 CSRF 토큰 사용에 대한 구체적인 요구사항은 다음과 같습니다.\n",
      "\n",
      "- 모든 상태 변경 요청에는 반드시 CSRF 토큰을 포함시켜야 합니다.\n",
      "- 쿠키의 SameSite 속성을 설정하여 CSRF 공격을 예방해야 합니다.\n",
      "\n",
      "이 두 가지 조치를 통해 CSRF 공격을 효과적으로 방지할 수 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "크로스사이트 요청 위조(CSRF) 방지 파트에서 CSRF 토큰 사용에 대한 구체적인 요구사항은 다음과 같습니다.\n",
      "\n",
      "- 모든 상태 변경 요청에는 CSRF 토큰을 포함시켜야 합니다.\n",
      "- 쿠키의 SameSite 속성을 설정하여 CSRF 공격을 예방해야 합니다.\n",
      "\n",
      "이와 같이 CSRF 토큰을 적절히 사용하고 SameSite 속성을 설정함으로써 크로스사이트 요청 위조 공격을 효과적으로 방지할 수 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"SameSite 쿠키 설정 방법\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"SameSite 쿠키 설정 방법\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 사내 문서 내에 SameSite 쿠키 설정 방법에 대한 구체적인 내용은 포함되어 있지 않습니다. 일반적으로 SameSite 쿠키 속성은 서버에서 Set-Cookie 헤더를 설정할 때 다음과 같이 지정합니다.\n",
      "\n",
      "- `SameSite=Strict` : 쿠키가 동일 사이트 요청에만 전송됩니다.\n",
      "- `SameSite=Lax` : 일부 크로스사이트 요청에 쿠키가 전송됩니다.\n",
      "- `SameSite=None; Secure` : 모든 크로스사이트 요청에 쿠키가 전송되며, Secure 속성이 반드시 함께 설정되어야 합니다.\n",
      "\n",
      "구체적인 설정 방법은 사용하는 서버 환경이나 프레임워크에 따라 다르므로, 해당 환경에 맞는 설정 방법을 참고하시기 바랍니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "사내 문서 내에서는 SameSite 쿠키 설정 방법에 대한 구체적인 절차나 코드 예시는 명시되어 있지 않습니다. 따라서, SameSite 쿠키 설정은 서버 측에서 쿠키를 생성할 때 SameSite 속성(예: 'Lax', 'Strict', 'None')을 명시적으로 설정하는 방식으로 이루어집니다. \n",
      "\n",
      "예를 들어, 웹 서버 설정 파일이나 프레임워크 기반의 코드에서 쿠키 생성 시 SameSite 속성을 지정하는 방식을 권장합니다. \n",
      "\n",
      "추가적인 세부 설정 방법에 대해서는 서버 기술 문서나 프레임워크 문서를 참고하시기 바랍니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"의존성 관리 섹션의 패키지 업데이트 주기\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"의존성 관리 섹션의 패키지 업데이트 중요성\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"의존성 관리 섹션의 패키지 업데이트 주기\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"의존성 관리 섹션의 패키지 업데이트 중요성\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 의존성 관리 섹션에서는 사용하는 라이브러리와 패키지를 정기적으로 업데이트하여 최신 보안 패치를 적용하는 것이 중요하다고 설명하고 있습니다. 또한, 의존성에 대한 취약점 스캐닝 도구를 사용하여 보안 취약점을 사전에 예방하는 점검도 강조하고 있습니다. 패키지 업데이트의 주기는 정기적으로 이루어져야 하며, 이를 통해 보안과 안정성을 유지하는 것이 중요하다고 명시되어 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "의존성 관리 섹션에서는 사용하는 라이브러리와 패키지를 정기적으로 업데이트하여 최신 보안 패치를 적용하는 것이 중요하다고 설명하고 있습니다. 또한, 의존성에 대한 취약점 스캐닝 도구를 활용하여 보안 취약점을 사전에 점검하는 절차도 포함되어 있습니다. 패키지 업데이트의 주기는 명확히 정해져 있지 않지만, 보안 및 기능 개선을 위해 정기적인 업데이트가 권장되는 점을 강조하고 있습니다.\n",
      "====================================================================================================\n",
      "레이블 : <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"취약점 스캐닝 도구 종류\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"취약점 스캐닝 도구 도입 및 운영 시 주의사항\"}}</tool_call>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: <tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"취약점 스캐닝 도구 종류\"}}</tool_call>\n",
      "<tool_call>{\"name\": \"frontend_search\", \"arguments\": {\"keyword\": \"취약점 스캐닝 도구 도입 및 운영 시 주의사항\"}}</tool_call>\n",
      "====================================================================================================\n",
      "레이블 : 문서에는 취약점 스캐닝 도구의 구체적인 종류나 명칭에 대한 언급은 없습니다. 다만, 의존성 관리 섹션에서 취약점 스캐닝 도구를 사용하여 의존성의 보안 취약점을 사전 예방적으로 점검해야 한다고 안내하고 있습니다. 또한, 도입 및 운영 시 주의사항에 대해서도 별도의 구체적인 안내는 포함되어 있지 않습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "모델의 예측: \n",
      "\n",
      "문서에는 구체적인 취약점 스캐닝 도구 종류에 대한 안내는 포함되어 있지 않으나, 의존성에 대한 취약점 스캐닝 도구를 사용하여 보안 취약점을 사전 예방적으로 점검하는 점을 강조하고 있습니다. 또한, 취약점 스캐닝 도구 도입 및 운영 시에는 정기적인 업데이트와 취약점 점검을 통해 보안 취약점을 사전에 발견하고 대응하는 절차가 필요하다는 점을 주의사항으로 안내하고 있습니다. 구체적인 도구 종류나 운영 세부 사항은 별도로 명시되어 있지 않습니다.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for label, pred in zip(df['label'].to_list()[:50], df['output'].to_list()[:50]):\n",
    "    print('레이블 :', label)\n",
    "    print('--' * 50)\n",
    "    print('모델의 예측:', pred)\n",
    "    print('==' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1014c5-9e8d-40f2-8c0a-d347b153c5a7",
   "metadata": {},
   "source": [
    "## 4. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54218952-e391-43f7-96a5-1835c5847905",
   "metadata": {},
   "source": [
    "아래 코드는 펑션 콜링 성능을 평가하기 위한 Python 함수를 구현한 것입니다. 요청하신 세 가지 메트릭을 다음과 같이 구현했습니다:\n",
    "\n",
    "- tool_selection: 함수 이름의 일치 여부를 평가합니다.\n",
    "- params_selection: 파라미터 키(예: user_id)의 일치 여부를 평가합니다.\n",
    "- params_value_accuracy: 파라미터 값(예: \"U002\")의 일치 여부를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb5c7369-3cf4-43d3-ac8b-daf4532af8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# ======================\n",
    "# 선택적 형태소 분석기 준비 (Okt -> Mecab -> fallback)\n",
    "# ======================\n",
    "def _try_import_tokenizers():\n",
    "    okt = None\n",
    "    mecab = None\n",
    "    try:\n",
    "        from konlpy.tag import Okt\n",
    "        okt = Okt()\n",
    "    except Exception:\n",
    "        pass\n",
    "    if okt is None:\n",
    "        try:\n",
    "            from konlpy.tag import Mecab\n",
    "            mecab = Mecab()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return okt, mecab\n",
    "\n",
    "_OKT, _MECAB = _try_import_tokenizers()\n",
    "_PUNCT_RE = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "_TOOL_CALL_RE = re.compile(r\"<tool_call>(.*?)</tool_call>\", re.DOTALL)\n",
    "_THINK_TAG_RE = re.compile(r\"<think>.*?</think>\", re.S)\n",
    "\n",
    "# ======================\n",
    "# 전처리 & 토크나이즈 & 유사도\n",
    "# ======================\n",
    "def normalize_text(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        try:\n",
    "            s = json.dumps(s, ensure_ascii=False, sort_keys=True)\n",
    "        except Exception:\n",
    "            s = str(s)\n",
    "    s = s.strip()\n",
    "    s = unicodedata.normalize(\"NFC\", s)\n",
    "    return s\n",
    "\n",
    "def tokenize_ko(s: str):\n",
    "    s = normalize_text(s)\n",
    "    s_clean = _PUNCT_RE.sub(\" \", s)\n",
    "    if _OKT is not None:\n",
    "        try:\n",
    "            return _OKT.morphs(s_clean)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if _MECAB is not None:\n",
    "        try:\n",
    "            return _MECAB.morphs(s_clean)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return s_clean.split()\n",
    "\n",
    "def jaccard(a_tokens, b_tokens):\n",
    "    a, b = set(a_tokens), set(b_tokens)\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def char_ratio(a: str, b: str):\n",
    "    a = normalize_text(a)\n",
    "    b = normalize_text(b)\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def morph_similarity(a, b, alpha=0.6):\n",
    "    \"\"\"\n",
    "    형태소 Jaccard(alpha) + 문자 유사도(1-alpha)\n",
    "    \"\"\"\n",
    "    a_tokens = tokenize_ko(a)\n",
    "    b_tokens = tokenize_ko(b)\n",
    "    j = jaccard(a_tokens, b_tokens)\n",
    "    c = char_ratio(a, b)\n",
    "    return alpha * j + (1 - alpha) * c\n",
    "\n",
    "# ======================\n",
    "# 보조: <think> 제거\n",
    "# ======================\n",
    "def strip_think(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return _THINK_TAG_RE.sub(\"\", s)\n",
    "\n",
    "# ======================\n",
    "# 메인 평가 함수 (유사도 점수만)\n",
    "# ======================\n",
    "def evaluate_function_calls_similarity(labels, predictions, alpha=0.6):\n",
    "    results = {\n",
    "        'tool_selection': {'correct': 0, 'total': 0},\n",
    "        'params_selection': {'correct': 0, 'total': 0},\n",
    "        'params_value_similarity': {'sum': 0.0, 'count': 0},\n",
    "    }\n",
    "    tool_call_count = 0\n",
    "\n",
    "    for label_raw, pred_raw in zip(labels, predictions):\n",
    "        label = strip_think(label_raw or \"\")\n",
    "        pred  = strip_think(pred_raw or \"\")\n",
    "\n",
    "        label_m = _TOOL_CALL_RE.search(label)\n",
    "        pred_m  = _TOOL_CALL_RE.search(pred)\n",
    "\n",
    "        if not label_m:\n",
    "            continue\n",
    "        tool_call_count += 1\n",
    "\n",
    "        if not pred_m:\n",
    "            results['tool_selection']['total'] += 1\n",
    "            results['params_selection']['total'] += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            label_json = json.loads(label_m.group(1))\n",
    "            pred_json  = json.loads(pred_m.group(1))\n",
    "        except json.JSONDecodeError:\n",
    "            results['tool_selection']['total'] += 1\n",
    "            results['params_selection']['total'] += 1\n",
    "            continue\n",
    "\n",
    "        # 1) 함수 이름 일치 정확도\n",
    "        results['tool_selection']['total'] += 1\n",
    "        if label_json.get('name') == pred_json.get('name'):\n",
    "            results['tool_selection']['correct'] += 1\n",
    "\n",
    "        # 2) 파라미터 키 일치 정확도\n",
    "        label_args = label_json.get('arguments', {}) or {}\n",
    "        pred_args  = pred_json.get('arguments', {}) or {}\n",
    "        label_keys = set(label_args.keys())\n",
    "        pred_keys  = set(pred_args.keys())\n",
    "\n",
    "        for k in label_keys:\n",
    "            results['params_selection']['total'] += 1\n",
    "            if k in pred_keys:\n",
    "                results['params_selection']['correct'] += 1\n",
    "        for k in pred_keys:\n",
    "            if k not in label_keys:\n",
    "                results['params_selection']['total'] += 1\n",
    "\n",
    "        # 3) 값 유사도 (공통 키만)\n",
    "        common = label_keys & pred_keys\n",
    "        if common:\n",
    "            sims = []\n",
    "            for k in common:\n",
    "                sims.append(morph_similarity(label_args.get(k), pred_args.get(k), alpha=alpha))\n",
    "            sample_sim = sum(sims) / len(sims)\n",
    "            results['params_value_similarity']['sum'] += sample_sim\n",
    "            results['params_value_similarity']['count'] += 1\n",
    "\n",
    "    final = {}\n",
    "    for metric in ('tool_selection', 'params_selection'):\n",
    "        c = results[metric]['correct']\n",
    "        t = results[metric]['total']\n",
    "        final[metric] = (c / t) if t else 0.0\n",
    "\n",
    "    sim_sum = results['params_value_similarity']['sum']\n",
    "    sim_cnt = results['params_value_similarity']['count']\n",
    "    final['params_value_similarity'] = (sim_sum / sim_cnt) if sim_cnt else 0.0\n",
    "\n",
    "    final['total_samples'] = tool_call_count\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2f1b8a-5e21-4c2a-bfcb-3d80a63ee51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_selection: 98.05%\n",
      "params_selection: 98.05%\n",
      "params_value_similarity: 88.50%\n",
      "total_samples: 308\n"
     ]
    }
   ],
   "source": [
    "labels = df['label'].to_list()\n",
    "preds = df['output'].to_list()\n",
    "\n",
    "results_with_errors = evaluate_function_calls_similarity(labels, preds, alpha=0.6)\n",
    "for metric, value in results_with_errors.items():\n",
    "    if metric != 'total_samples':\n",
    "        print(f\"{metric}: {value:.2%}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ff9f2-f541-497d-9a3e-66d20229ce31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
