{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-23T04:56:30.866029Z",
     "start_time": "2025-09-23T04:54:57.125235Z"
    }
   },
   "source": [
    "import os, json, glob\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Iterable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# ===== 설정 =====\n",
    "INPUT_DIR = \"./COMPANY_DATA/cto\"                 # 텍스트 문서 폴더(.txt/.md/.html)\n",
    "OUTPUT_JSONL = \"./qa_dataset.jsonl\"  # 결과 저장 경로\n",
    "PAIRS_PER_CHUNK = 4                  # 조각당 생성할 Q/A 개수\n",
    "CHUNK_SIZE = 2500                    # 문자 기준 조각 크기\n",
    "CHUNK_OVERLAP = 250                  # 조각 겹침\n",
    "\n",
    "def query_setting_for_internal_documents():\n",
    "    return ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "    )\n",
    "\n",
    "llm = query_setting_for_internal_documents()\n",
    "\n",
    "# ===== 간단 유틸 =====\n",
    "def iter_text_files(root: str) -> Iterable[str]:\n",
    "    for pattern in (\"**/*.txt\", \"**/*.md\", \"**/*.html\", \"**/*.htm\"):\n",
    "        yield from (p for p in glob.glob(os.path.join(root, pattern), recursive=True) if os.path.isfile(p))\n",
    "\n",
    "def read_text(path: str) -> str:\n",
    "    # 인코딩 오류만 가볍게 우회\n",
    "    try:\n",
    "        return Path(path).read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return Path(path).read_text(encoding=\"cp949\", errors=\"ignore\")\n",
    "\n",
    "def chunk_text(s: str, size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
    "    if not s:\n",
    "        return []\n",
    "    chunks = []\n",
    "    i, n = 0, len(s)\n",
    "    while i < n:\n",
    "        start = max(0, i - (overlap if i else 0))\n",
    "        end = min(n, i + size)\n",
    "        chunks.append(s[start:end])\n",
    "        i += size if i == 0 else (size - overlap)\n",
    "    return chunks\n",
    "\n",
    "# ===== 프롬프트 (사내 실무형) =====\n",
    "SYSTEM = SystemMessage(content=(\n",
    "    \"너는 기업 내부 문서 전용 Q&A 데이터셋을 생성하는 어시스턴트다. \"\n",
    "    \"주어진 '문서 조각'만을 근거로, 사내 직원이 사내 문서 챗봇에게 할 법한 실제 실무형 질문과 그에 대한 정답을 생성하라. \"\n",
    "    \"외부 지식을 섞지 말고, 문서 조각에 답이 명시적으로 존재하는 질문만 만들 것.\"\n",
    "))\n",
    "\n",
    "USER_TMPL = (\n",
    "    \"다음은 회사 내부 문서의 일부다. 이 조각만 보고 정확히 답할 수 있는 \"\n",
    "    \"실무형 사내 질문/정답 페어를 최대 {k}개 생성하라.\\n\\n\"\n",
    "    \"요구사항:\\n\"\n",
    "    \"- 질문은 사내 직원이 문서 챗봇에 묻는 자연스러운 톤(예: 설정/권한/절차/에러핸들링/운영규칙/SOP 등)\\n\"\n",
    "    \"- 답변은 반드시 문서 조각에 근거하여 구체적이고 정확하게 작성\\n\"\n",
    "    \"- 외부 지식 금지, 조각에 근거 없는 질문 금지\\n\"\n",
    "    \"- 출력은 JSON 객체 하나로만 반환\\n\\n\"\n",
    "    \"문서 조각:\\n\\n{chunk}\\n\\n\"\n",
    "    \"출력 스키마 예시:\\n\"\n",
    "    \"{{\\\"pairs\\\": [{{\\\"question\\\": \\\"...\\\", \\\"answer\\\": \\\"...\\\"}}]}}\"\n",
    ")\n",
    "\n",
    "def generate_pairs(chunk: str, k: int) -> List[Dict[str, str]]:\n",
    "    messages = [SYSTEM, HumanMessage(content=USER_TMPL.format(chunk=chunk, k=k))]\n",
    "    # 최소한의 재시도(네트워크 흔들림 대비). 과도한 검증 제거.\n",
    "    for _ in range(2):\n",
    "        try:\n",
    "            resp = llm.invoke(messages)\n",
    "            data = json.loads(resp.content)\n",
    "            return data.get(\"pairs\", [])\n",
    "        except Exception:\n",
    "            pass\n",
    "    # 실패 시 빈 리스트\n",
    "    return []\n",
    "\n",
    "def save_jsonl(rows: List[Dict[str, Any]], path: str):\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def build_dataset(input_dir: str, out_path: str):\n",
    "    total = 0\n",
    "    for fp in iter_text_files(input_dir):\n",
    "        text = read_text(fp).strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        for chunk in chunk_text(text):\n",
    "            pairs = generate_pairs(chunk, PAIRS_PER_CHUNK)\n",
    "            if not pairs:\n",
    "                continue\n",
    "            rows = [{\"question\": p[\"question\"], \"reference\": [chunk], \"answer\": p[\"answer\"]}\n",
    "                    for p in pairs if \"question\" in p and \"answer\" in p]\n",
    "            if rows:\n",
    "                save_jsonl(rows, out_path)\n",
    "                total += len(rows)\n",
    "    print(f\"✅ 생성 완료: {total}개 저장 → {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_dataset(INPUT_DIR, OUTPUT_JSONL)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 생성 완료: 64개 저장 → ./qa_dataset.jsonl\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5b4ba557ed61e8fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
